{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Predicting sentiment from product reviews\n",
                "\n",
                "The goal of this first notebook is to explore logistic regression and feature engineering with sklearn.\n",
                "\n",
                "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative. Specifically, you will:\n",
                "\n",
                "* Use a Pandas Dataframes to do feature engineering\n",
                "* Train a logistic regression model to predict the sentiment of product reviews.\n",
                "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
                "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
                "* Given a classifier, create a confusion matrix\n",
                "* Compare multiple logistic regression models.\n",
                "\n",
                "\n",
                "Copyright ©2023 Emily Fox, Hunter Schafer, Valentina Staneva.  All rights reserved.  Permission is hereby granted to students registered for University of Washington CSE/STAT 416 for use solely during Spring Quarter 2024 for purposes of the course.  No other use, copying, distribution, or modification is permitted without prior written consent. Copyrights for third-party components of this work must be honored.  Instructors interested in reusing these course materials should contact the author.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import string\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.feature_extraction import DictVectorizer\n",
                "\n",
                "sns.set()\n",
                "%matplotlib inline"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data preparation\n",
                "\n",
                "We will use a dataset consisting of food product reviews on Amazon.com [source](http://jmcauley.ucsd.edu/data/amazon/).\n",
                "\n",
                "**NOTE**: Be sure to run every cell in the notebook! The `###SKIP` is for the autograder. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eproduct_id\u003c/th\u003e\n      \u003cth\u003esummary\u003c/th\u003e\n      \u003cth\u003ereview\u003c/th\u003e\n      \u003cth\u003erating\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e4408\u003c/td\u003e\n      \u003ctd\u003eDoes increase milk supply\u003c/td\u003e\n      \u003ctd\u003eThis really helped to increase my milk supply....\u003c/td\u003e\n      \u003ctd\u003e3.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e4209\u003c/td\u003e\n      \u003ctd\u003eOne bad packet ruins the product!\u003c/td\u003e\n      \u003ctd\u003eI should have stayed with Idahoan brand. Poor ...\u003c/td\u003e\n      \u003ctd\u003e1.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e8623\u003c/td\u003e\n      \u003ctd\u003eCAULIFLOWER PASTA!?\u003c/td\u003e\n      \u003ctd\u003eAs the pasta cooked, I read the box to see wha...\u003c/td\u003e\n      \u003ctd\u003e4.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e9439\u003c/td\u003e\n      \u003ctd\u003eTasty and inexpensive\u003c/td\u003e\n      \u003ctd\u003eI really like this cereal. The flavor is sligh...\u003c/td\u003e\n      \u003ctd\u003e5.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e7110\u003c/td\u003e\n      \u003ctd\u003eI'm Confused\u003c/td\u003e\n      \u003ctd\u003eThe label on the bowl says 35 grams is in the ...\u003c/td\u003e\n      \u003ctd\u003e2.0\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e",
                        "text/plain": "   product_id                            summary  \\\n0        4408          Does increase milk supply   \n1        4209  One bad packet ruins the product!   \n2        8623                CAULIFLOWER PASTA!?   \n3        9439              Tasty and inexpensive   \n4        7110                       I'm Confused   \n\n                                              review  rating  \n0  This really helped to increase my milk supply....     3.0  \n1  I should have stayed with Idahoan brand. Poor ...     1.0  \n2  As the pasta cooked, I read the box to see wha...     4.0  \n3  I really like this cereal. The flavor is sligh...     5.0  \n4  The label on the bowl says 35 grams is in the ...     2.0  "
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "### SKIP\n",
                "products = pd.read_csv('food_products.csv')\n",
                "\n",
                "# Set seed for the whole program\n",
                "np.random.seed(416)\n",
                "\n",
                "products.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Do not modify the below cell. It configures the autograder, which will award 0 points if it doesn't run."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_load_data) ###"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Extract sentiments\n",
                "\n",
                "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment. Let's see how many of each rating we have."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "89"
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "products = products[products['rating'] != 3].copy()\n",
                "\n",
                "len(products)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "\u003cAxes: title={'center': 'Number of reviews with a given rating'}, xlabel='rating', ylabel='Count'\u003e"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAHKCAYAAADhBVpHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAUUlEQVR4nO3deXiNd/7/8dc5WQQRhNARSy1NiMTSFkFtQUcrSimjHaVtatfoTlHf1ig6WlRsY51q1bRaXFODbrZRS2dara06glaZKUElsSSRc+7fH5rz65GErM45nz4f1+Xi3Nt5v+9Pzu2V+77POTbLsiwBAAAYxu7pAgAAAEoDIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhB6Vq9erVioyMVExMjE6ePJlr/sMPP6z4+HgPVCbt3r1bkZGR2rhxo0eev7BOnDihIUOGqGXLloqMjNQrr7zi6ZJc+3D37t2eLqXUREZGKikpyfU4OTlZSUlJOnHiRK5lPfnzXBhxcXEaO3asp8soVadOnVJSUpK+/fbbXPOSkpIUGRnpgapws/l7ugD8NmRlZWnWrFmaPn26p0vxWVOnTtU333yjKVOmqGrVqgoLC/N0SWrcuLHeffddNWjQwNOllJp3331Xt9xyi+txcnKy5syZo5YtW6pmzZoerKzo5syZo+DgYE+XUapOnz6tOXPmKDw8XI0aNXKb17dvX7Vr185DleFmIuTgpmjXrp3WrVunhIQENWzY0NPl3FQZGRkqU6aMbDZbsbZz+PBhNWnSRF26dCn0upZlKTMzU0FBQcWq4VrBwcFq1qxZiW7T25jYX1RUlKdLKLSSeh1J0i233OIWXGEuLlfhpnj88cdVqVKlG57JOXHihCIjI7V69epc8669bJBzyvnQoUNKTEzUHXfcoZYtW2rq1KnKzs7W0aNHlZCQoObNmysuLk6LFi3K8zkzMzM1depUtW3bVk2aNNGAAQN08ODBXMvt27dPw4YNU8uWLRUTE6NevXpp/fr1bsvkXJ7bvn27XnjhBcXGxqpp06bKysrKt+f//ve/evbZZ9W6dWtFR0frnnvu0dKlS+V0OiX9/0tCP/zwg7Zt26bIyEhFRkbmebnk1/tq0qRJWrlype655x7FxMRozZo1kqTvv/9ezzzzjNvzrVixwrXuuXPnFB0drVmzZuXa7pEjRxQZGanly5e71Xbt5aob7asLFy4oKipKixcvdnvehg0b6o477lB2drZr+uTJkxUbG6uc7xI+ePCghg4d6qr/rrvu0pAhQ/TTTz/luz9WrFihhg0b6uzZs65pS5cuVWRkpF5++WXXNKfTqRYtWmjatGlu+zLn52716tUaPXq0JGngwIGusbj253Xv3r166KGH1LRpU3Xu3FkLFy50jef1rFixQn/84x/VunVrNWvWTD169NCiRYt05cqVG64rSZ9++ql69Oih6Ohode7cWW+++Wael2Z+fbmqMOMtSSkpKZo4caLat2+v6OhoxcXFac6cOW5jlvM6XrJkiZYtW6a4uDg1b95cf/jDH/T111/fsI/rvY5++OEHvfDCC7r77rvVtGlTtWvXTsOGDdN3333nWn/37t164IEHJEkvvPCCa5xyxjG/fTJ06FBt27ZN999/v5o0aaJu3brp/fffz1Xfv//9b/3hD39QTEyM2rVrp1mzZmnVqlU3fF3i5uNMDm6K8uXLa/jw4XrllVe0c+dOtW7dusS2/eSTT+q+++5T//799fnnn2vx4sXKzs7Wjh079NBDDykhIUEffvihXnvtNdWpU0d333232/ozZ85UVFSUJk+erPT0dM2ZM0cPP/yw1q5dq1q1akmSdu3apccff1xNmzbVSy+9pAoVKmj9+vV66qmnlJGRod69e7ttc9y4cerYsaP+/Oc/6/Lly/L3z/uldu7cOfXv319XrlzR6NGjFR4eri1btujVV1/V8ePH9dJLL7kuCY0aNUq1atXSmDFjJEnVqlW77n759NNP9e9//1sjR45U1apVVaVKFSUnJ6t///763e9+pzFjxigsLEzbt2/X5MmT9fPPP2vUqFEKDQ1Vx44dtXbtWiUmJspu//+/C61evVoBAQHq0aNHvs9bkH0VHBysmJgY7dy5U48//rhrvcDAQF28eFF79+7V7bffLknasWOHYmNjZbPZdOnSJT366KOqWbOmJk6cqKpVqyolJUW7d+/WxYsX862pdevWsixLO3fudN0zs2PHDgUFBWnHjh2u5fbv36+0tLR8fz47duyop59+WjNmzNDEiRPVuHFjSVLt2rVdy6SkpOi5557To48+qlGjRumTTz7R66+/rmrVqqlXr17XHbPjx48rPj5eNWvWVEBAgA4dOqQFCxbo6NGjmjp16nXX3bZtm5544gndeeedmjVrlrKzs7V06VKdOXPmuusVZrxTUlLUt29f2e12jRw5UrVr19aePXs0f/58nTx5MleNK1asUL169TRu3DhJ0htvvKEhQ4bos88+U4UKFa5bl5T36+j06dOqVKmSnnnmGYWGhio1NVVr1qxRv379tGbNGtWrV0+NGzfW1KlT9cILL2j48OHq2LGjJN3w7M2hQ4f06quvavDgwapatapWrVql8ePHq06dOmrRooVrmccee0y33nqrXn31VQUFBelvf/ub/v73v9+wH3iABZSiDz74wIqIiLD27t1rZWZmWp07d7Z69+5tOZ1Oy7Isa8CAAVb37t1dy//4449WRESE9cEHH+TaVkREhDV79mzX49mzZ1sRERHW0qVL3Zbr2bOnFRERYX388ceuaVeuXLFiY2OtUaNGuabt2rXLioiIsO6//35XPZZlWSdOnLAaN25sjR8/3jWtW7duVq9evawrV664PdfQoUOttm3bWg6Hw63f559/vkD757XXXrMiIiKsb775xm36//3f/1mRkZHW0aNHXdM6depkDRkypEDbjYiIsO644w7r/PnzbtMfe+wxq3379lZ6errb9EmTJlkxMTGu5T/77DMrIiLC2r59u2uZ7Oxs66677rKeeOIJ17Scfbhr1y7XtILuq5kzZ1pNmjSxMjMzLcuyrPHjx1sJCQlWjx49rKSkJMuyLOunn36yIiIirHfffdeyLMvat2+fFRERYX3yyScF2g+/1r59e+uFF16wLMuyMjMzrWbNmlnTp0+3IiIirJMnT1qWZVnz58+3GjdubF28eNG13rU/dxs2bMjVc44BAwbkOZ733nuv9dhjjxWqXofDYV25csVas2aN1ahRo1xjea0+ffpYHTp0cO1Py7KsCxcuWC1btrQiIiLclu3UqZM1ZswY1+OCjveLL75oNWvWzLW/cixZssSKiIiwDh8+bFnW/38dx8fHW9nZ2a7lvvnmGysiIsJat27ddXspzOsoOzvbysrKsu6++25rypQprul79+7N91iSc+z4tU6dOlkxMTFuvWVkZFgtW7a0XnzxRde0xMREq1mzZtbZs2dd0xwOh3XvvfdaERER1o8//njDmnHzcLkKN01gYKCefPJJ7d+/Xxs2bCix7eb8lpajfv36stlsat++vWuav7+/6tSpk+c7vOLj492u84eHh6t58+auSzA//PCDjh496vptNjs72/Wnffv2SklJ0bFjx9y2ee3Zovzs2rVLDRo0UJMmTdym9+7dW5ZladeuXQXaTl5iY2NVsWJF1+PMzEzt2rVLXbt2VVBQUK4+MjMzXZcS2rdvr7CwMLfLMNu3b9fp06fVp0+ffJ+zMPuqdevWysjI0FdffSXp6pmVtm3bqk2bNq6zKzt37nQtK0l16tRRxYoV9dprr2nlypVKTk4u8P5o3bq1a3t79uzR5cuX9eijj6py5cr6/PPPXTU0a9ZM5cqVK/B2rxUWFpZrPCMjI/Xf//73husePHhQw4YNU6tWrdSoUSM1btxYY8aMkcPh0Pfff5/vepcuXdL+/fvVpUsXBQYGuqaXL19ecXFxN3zego73li1b1KpVK1WrVi3X2ErSF1984bbdjh07ys/Pz/U45368vF6HecnrdZSdna0FCxbo3nvvVXR0tKKiohQdHa3vv/9eR44cKdB289OoUSPVqFHD9bhMmTK69dZb3cbuX//6l1q1aqXQ0FDXNLvdrnvuuadYz43SweUq3FTdu3fX0qVLNXPmTHXt2rVEtvnr/8glKSAgQGXLllWZMmVyTb9w4UKu9atWrZrntEOHDkmS63T/q6++qldffTXPGn7++We3xwV959P58+cVHh6ea3rOpajz588XaDt5ubaG8+fPKzs7W2+99ZbeeuutPNfJ6cPf31/33Xef3n77baWlpSkkJESrV69WWFiY7rrrrnyfszD7qnnz5ipbtqx27typ3/3udzp58qTatGmjn376SW+//bYuXryoHTt2qFatWq7LhhUqVNBbb72lBQsWaObMmUpNTVVYWJj69eun4cOHKyAgIN/aWrdurTVr1uj777/Xjh07FBUVpSpVqig2NlY7d+5Ujx49tGfPHg0bNizfbRREpUqVck0LDAxUZmbmddf773//qz/+8Y+qW7euxo0bp/DwcJUpU0Z79+7VpEmTlJGRke+6aWlpsixLVapUyTUvr2nXKuh4nz17Vps3b3ZdprvWta+Da/dFTgC70b7IkdfraNq0aVqxYoUGDx6sFi1aqGLFirLZbJowYUKBt5ufgozd+fPn8zxmFGQ/4+Yj5OCmstlsevbZZ/Xoo4/qvffeyzU/J5hce6PutQfPkpTXPQtnzpxxHfAqV64sSRo6dGi+waxu3bpujwv6DpBKlSopJSUl1/TTp0+7PXdRXFtDSEiI/Pz81LNnTz300EN5rvPrt0T36dNHS5Ys0T/+8Q/de++92rRpkwYNGuT2m/m1CrOvAgMDdccdd2jHjh2qXr26wsLCFBkZ6Qo0X3zxhXbu3KlOnTq5rR8ZGamZM2fKsix99913Wr16tebOnaugoCANGTIk39pyzgbt2LFDO3bsUJs2bVzTZ82apX/961/KyspyTb/ZPv30U126dElJSUluwTcnbF9PSEiIbDab243VOW50T06Ogox35cqVFRkZqSeffDLPbdzoPrHCyut19Pe//129evXS008/7Tb9559/VkhISIk+f14qVaqU7zED3oeQg5uuTZs2atu2rebOnZvrRsCqVauqTJkybu+UkKTPPvus1OpZt26dHn30UdcB9eTJk9qzZ4969uwpSapXr55uvfVWHTp0KNeBtbhat26tv/zlLzpw4IDbb8dr166VzWZTq1atSuy5ypYtq1atWungwYOKjIx0u6yRl/r166tp06ZavXq1nE6nsrKyct1gfa3C7qvWrVtrxowZKl++vCuElCtXTk2bNtXbb7+t06dP53sTsM1mU8OGDTVu3DitWbNGBw4cuO5zVatWTQ0aNNDHH3+sAwcOuOpr06aNJk6cqL/+9a+uG6KvJ2e/Xe/MSlHk/Pz9elwsy8rzl4FrlStXTtHR0fr000/1/PPPu7Zx8eJFbd68uUDPX5Dx7tixo7Zu3aratWvnOoN6s9hstlxn7LZs2aJTp06pTp06rmmlNU4tWrTQtm3bdO7cOdclK6fT6TMfKvpbQ8iBRzz77LPq3bu3zp49q9tuu8013Waz6b777tMHH3yg2rVrq2HDhtq7d6/WrVtXarWcO3dOI0eOVL9+/ZSenq6kpCQFBgZq6NChrmVefvllDR48WAkJCbr//vtVvXp1paam6siRIzpw4IBmz55dpOd+5JFHtHbtWg0dOlSJiYmqUaOGtmzZonfeeUcPPvhgrjNExTV+/Hg99NBD+uMf/6gHH3xQ4eHhunjxoo4fP65Nmza5vVVYuvrb/cSJE3X69Gk1b95c9erVu+FzFGZftW7dWg6HQzt37nS7vNW6dWslJSXJZrMpNjbWNX3z5s1655131KVLF9WqVUuWZenjjz9WWlqa2rZte8PaWrdurbfeektBQUGud2/VqlVLNWvW1Pbt2xUXF5fvO+Fy5Py8vvfeeypfvrzKlCmjmjVrFuusm3Q1bAUEBOjpp5/W448/rqysLK1cuVJpaWkFWj8xMVFDhw5VQkKCBg0aJIfDoSVLlqh8+fJKTU0t0DZuNN6JiYnasWOH+vfvr4cfflh169ZVVlaWTpw4oW3btunll18u9c+f6dixo+tdVJGRkTpw4ICWLFmS63lr166toKAgffjhh6pfv77KlSunatWqqXr16sV6/uHDh2vz5s165JFHNGzYMNe7qy5fvixJbu9Og+cxGvCIqKgode/ePc95Y8eO1X333afFixdrxIgR2rNnjxYsWFBqtTz11FOqUaOGXnjhBY0bN05hYWFavny529uCY2NjtWrVKlWoUEFTpkzRo48+qpdeesntskdRhIaG6m9/+5tatWql119/XcOGDdP27dv13HPP6cUXXyyJ9tw0aNBAq1ev1m233aZZs2YpISFB48eP18aNG/M8Y9K9e3cFBQXpp59+uu4Nx79WmH0VFRXlCge/fv6c5X49X7p643FISIgWL16s4cOHa/To0Tp48KCmTZumfv363bC2nOe444473O7Zynm+goxlrVq1NG7cOB06dEgDBw7UAw88UOCzJddTv359JSUlKS0tTU888YT+9Kc/qWHDhho/fnyB1m/fvr2SkpJ0/vx5Pfnkk5o2bZq6dOmiuLi4Al/GudF4V6tWTe+//77atm2rJUuWaPDgwXr++ef1wQcfqGHDhjflctH48eN13333aeHChRo+fLg2bdqkpKQkt9erdPXM5ZQpU3T+/HklJCTogQceKNBZsRtp2LChli5dqqCgII0ZM0YTJ05UgwYN9OCDD0pSgd4aj5vHZlm/fMIWAMAoV65cUa9evVS9enUtXbrU0+UY7bHHHtPJkyf10UcfeboU/AqXqwDAEOPGjVPbtm0VFhamM2fOaOXKlTpy5EiBzwahYKZOnapGjRrpd7/7nVJTU/Xhhx/q888/94ovzYU7Qg4AGOLixYt69dVXde7cOQUEBCgqKkoLFy702DvGTOVwODR79mydOXNGNptN9evX15///GfXmxXgPbhcBQAAjMSNxwAAwEiEHAAAYCRCDgAAMBIhBwAAGOk3/e4qy7LkdJbOfdd2u63Utu0NTO9PMr9H+vN9pvdIf76vNHq0220F/n7A33TIcTotnTt3scS36+9vV+XK5ZWWdknZ2c4S376nmd6fZH6P9Of7TO+R/nxfafUYGlpefn4FCzlcrgIAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwkr+nCwAA4LfKz8/ccw3e0BshBwCAm8xms8nptBQSUtbTpZQqp9OSzWbz2PMTcgAAuMnsdpvsdptWfnRIp85e9HQ5paJ6lfJ68PcNZbcTcgAA+M05fe6STqZc8HQZpcKTZ3ByeP6CGQAAQCkg5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwksdDzj//+U8NGDBAsbGxio6OVufOnTV16lSlp6e7Lbd161b16tVLMTEx6tq1q1asWOGhigEAgC/w93QBqampat68uQYNGqSQkBAdPnxYSUlJOnz4sJYuXSpJ2rNnj0aMGKGePXtq7Nix+uqrrzR58mQFBgaqb9++Hu4AAAB4I4+HnPj4eMXHx7set2rVSoGBgXrxxRd16tQpVa9eXXPnzlVUVJSmTJkiSYqNjdX//vc/vfHGG+rTp4/sdo+fkAIAAF7GK9NBpUqVJEnZ2dnKysrSrl271L17d7dlevTooZSUFB08eNADFQIAAG/n8TM5ORwOh7Kzs5WcnKy5c+eqU6dOCg8PV3Jysq5cuaJ69eq5Ld+gQQNJ0pEjRxQdHV3k5/X3L/mc5+dnd/vbNKb3J5nfI/35PtN7NL0/u9129R82yWazebaY0vJLW3a7rVT+ry0Irwk5nTp10qlTpyRJ7dq104wZMyRdvWdHkkJCQtyWz3mcM78o7HabKlcuX+T1byQkpGypbdsbmN6fZH6P9Of7TO/R9P787Hb5+/t5uoxS4ffLrSTBwUEeq8FrQs7ChQt16dIlJScna968eRo2bJiWLVvmmp9f0i1OAnY6LaWlXSry+vnx87MrJKSs0tIuy+Fwlvj2Pc30/iTze6Q/32d6j6b3FxDgp+DgIDmcTmVnOzxdTqlwOK+O24ULGbpypeR6DAkpW+AzfF4Tcho2bChJuv322xUVFaU+ffrok08+cV2WuvaMTVpamqTcZ3gKKzu79F48DoezVLfvaab3J5nfI/35PtN7NLU/13/SlmRZlmeLKS2/tOV0Wh4bQ6+82NmoUSP5+fnp+PHjql27tgICAnT06FG3ZZKTkyVJ9evX90SJAADAy3llyNmzZ48cDodq1qypwMBAxcbGasOGDW7LrFu3TmFhYYqKivJQlQAAwJt5/HLVqFGjFB0drcjISAUFBenQoUNavHixIiMj1aVLF0nSyJEjNWDAAE2YMEE9evTQV199pVWrVmnSpEl8Rg4AAMiTx0NOkyZNtH79ei1cuFCWZSk8PFz9+vVTQkKCAgMDJUnNmzfXvHnzNGPGDK1du1a33HKLJkyYwKcdAwCAfHk85AwZMkRDhgy54XIdOnRQhw4dbkJFAADABFzrAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjOTv6QIAb+bnZ+bvAab2BQC/RsgB8mCz2eR0WgoJKevpUkqN02nJZrN5ugwAKDWEHCAPdrtNdrtNKz86pFNnL3q6nBJXvUp5Pfj7hrLbCTkAzEXIAa7j9LlLOplywdNllDjO4AD4LeDCPAAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICR/D1dwIYNG/Thhx/qwIEDSk1NVa1atfTggw+qf//+stuvZrCxY8dqzZo1udZdtGiR2rdvf7NLBgAAPsDjIWfZsmWqUaOGnn/+eVWpUkW7d+/WK6+8oh9//FFjxoxxLVerVi299tprbuvWr1//ZpcLAAB8hMdDzoIFCxQaGup6HBsbq0uXLmnFihV66qmnFBgYKEkKCgpSs2bNPFQlAADwNR6/J+fXASdHo0aNlJmZqfPnz9/8ggAAgBE8fiYnL19++aUqVaqkKlWquKYdP35cd955pzIyMhQREaERI0aoS5cuxX4uf/+Sz3l+fna3v01jen+SZLfbrv7DJtlsNs8WUxp+aclut5XKa8DTfgs/o6b3aHp/xh9jJK84znhdyNm3b59Wr16tkSNHys/PT9LVMzsxMTFq0KCB0tPTtXLlSo0cOVJvvPGGunXrVuTnstttqly5fEmVnktISNlS27Y3ML0/SfKz2+Xv7+fpMkqc3y839QcHB3m4ktL1W/gZNb1H0/sz9RgjecdxxqtCTkpKihITExUTE6PBgwe7pg8aNMhtubi4OPXv31+zZ88uVshxOi2lpV0q8vr58fOzKySkrNLSLsvhcJb49j3N9P4kKSDAT8HBQXI4ncrOdni6nBLncF4dtwsXMnTlinn9/RZ+Rk3v0fT+TD/GSKV3nAkJKVvgM3xeE3LS09M1ePBgBQUFaf78+QoICMh3WbvdrrvvvlvTp09XRkaGgoKKnhKzs0vvxeNwOEt1+55mcn+uF5AlWZbl2WJKwy8tOZ2WsWMomf0zmsP0Hk3tz/hjjOQVxxmvCDmZmZkaPny4zpw5o3fffVeVK1e+4TrG/lAAAIAS4fGQk52drdGjR+vQoUN6++23FR4efsN1nE6nPvroI912223FOosDAADM5fGQM2nSJG3evFnPPfecMjIy9PXXX7vmNWjQQKmpqRo7dqzi4+NVu3ZtpaamauXKldq/f7+SkpI8VzgAAPBqHg8527dvlyRNnz4917zly5crMjJSwcHBmjt3rs6dO6eAgABFR0dr0aJFateu3c0uFwAA+AiPh5xNmzbdcJn58+ffhEoAAIBJzPyUJQAA8JtHyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAI/l7ugCT+fmZmSFN7QsAYBZCTimw2WxyOi2FhJT1dCmlxum0ZLPZPF0GAAD5IuSUArvdJrvdppUfHdKpsxc9XU6Jq16lvB78fUPZ7YQcAID3IuSUotPnLulkygVPl1HiOIMDAPAF3FwBAACMRMgBAABGIuQAAAAjeTzkbNiwQSNGjFCHDh3UrFkz9ejRQ++8846cTqfbclu3blWvXr0UExOjrl27asWKFR6qGAAA+AKP33i8bNky1ahRQ88//7yqVKmi3bt365VXXtGPP/6oMWPGSJL27NmjESNGqGfPnho7dqy++uorTZ48WYGBgerbt6+HOwAAAN7I4yFnwYIFCg0NdT2OjY3VpUuXtGLFCj311FMKDAzU3LlzFRUVpSlTpriW+d///qc33nhDffr0kd3u8RNSAADAy3g8Hfw64ORo1KiRMjMzdf78eWVlZWnXrl3q3r272zI9evRQSkqKDh48eLNKBQAAPsTjZ3Ly8uWXX6pSpUqqUqWKjh07pitXrqhevXpuyzRo0ECSdOTIEUVHRxf5ufz9Sz7nuT4kz2boZ8r80pLdbiuV/ecNGEPflvPVIyZ/BYnpPZren/HHGMkrjjNeF3L27dun1atXa+TIkfLz81NqaqokKSQkxG25nMc584vCbrepcuXyRS/2Bvzsdvn7+5Xa9j3F75fLg8HBQR6upPQxhr7N5K9WyWF6j6b3Z+oxRvKO44xXhZyUlBQlJiYqJiZGgwcPdpuXX9ItTgJ2Oi2lpV0q8vr5CQjwU3BwkBxOp7KzHSW+fU9z/PLOtwsXMnTlinn9SYyhr/PzsyskpKzS0i7L4XDeeAUfZHqPpvdn+jFGKr3jTEhI2QKf4fOakJOenq7BgwcrKChI8+fPV0BAgCSpYsWKknKfsUlLS5OU+wxPYWVnl/yLx7XzLcmyrBLfvsf90pLTaZXK/vMGjKEZHA6n0f1J5vdoan/GH2MkrzjOeMXFzszMTA0fPlxnzpzR4sWLVblyZde82rVrKyAgQEePHnVbJzk5WZJUv379m1orAADwDR4POdnZ2Ro9erQOHTqkxYsXKzw83G1+YGCgYmNjtWHDBrfp69atU1hYmKKiom5muQAAwEd4/HLVpEmTtHnzZj333HPKyMjQ119/7ZrXoEEDBQcHa+TIkRowYIAmTJigHj166KuvvtKqVas0adIkPiMHAADkyeMhZ/v27ZKk6dOn55q3fPlytWrVSs2bN9e8efM0Y8YMrV27VrfccosmTJjApx0DAIB8eTzkbNq0qUDLdejQQR06dCjlagAAgCm41gMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYKQihZxGjRpp7969ec7bv3+/GjVqVKyiAAAAiqtIIed6XybmdDqL9c3gAAAAJaHEL1cdOHBAFSpUKOnNAgAAFEqBP/H4zTff1PLlyyVJNptNI0eOVGBgoNsymZmZOnv2rH7/+9+XbJUAAACFVOCQU6VKFd12222SpJMnT6pWrVoKCQlxWyYwMFAREREaOHBgyVYJAABQSAUOOfHx8YqPj5ckPfzww3rppZdUv379UisMAACgOIr0BZ1vvfVWSdcBAABQoor8LeSWZWnfvn06efKkMjMzc83v1atXceoCAAAoliKFnGPHjmn48OH64Ycf8nw7uc1mI+QAAACPKlLImTRpkrKysjRz5kxFRkbmepcVAACApxUp5Ozdu1d/+tOf1K1bt5KuBwAAoEQU6cMAy5Urp+Dg4JKuBQAAoMQUKeT07t1b69atK+laAAAASkyRLldFREToH//4h4YNG6a4uDhVqlQp1zJ33313cWsDAAAosiKFnGeeeUaSdOLECW3ZsiXXfJvNpm+//bZYhQEAABRHkUJOzndYAQAAeKsihZyWLVuWdB0AAAAlqkg3HgMAAHi7Ip3JudG3jNtsNr355ptFKggAAKAkFCnk5PVVDufPn9exY8cUGhqqW2+9tbh1AQAAFEuJfgv5sWPHNGLECI0aNapYRQEAABRXid6TU7duXSUkJGj69OkluVkAAIBCK/Ebj8PDw3X48OGS3iwAAEChlHjI+fjjj1WtWrWS3iwAAEChFOmenBdeeCHXtKysLP3nP/9RcnKynnvuuWIXBgAAUBxFCjm7d+/ONa1MmTIKDw/XkCFD1KNHj2IXBgAAUBxFCjmbNm0q6ToAAABKFJ94DAAAjFSkMznS1Q//++tf/6pdu3bp559/VuXKldWmTRsNGjRIFStWLMkaAQAACq1IZ3JOnTql3r17a8GCBUpPT1eNGjWUnp6uefPm6f7779epU6dKuk4AAIBCKdKZnBkzZigjI0PvvfeemjRp4pq+d+9eDR8+XDNnztS0adNKrEgAAIDCKtKZnH/+85968skn3QKOJDVp0kSJiYnatm1biRQHAABQVEUKOenp6QoPD89zXs2aNZWenl6sogAAAIqrSCGnZs2a2rJlS57ztm3bppo1axanJgAAgGIr0j05vXv31uuvvy7LstSrVy+FhYUpJSVFf//73/X222/rmWeeKek6AQAACqVIIefxxx/Xjz/+qLffflsrVqxwTbcsS/369VNCQkKJFQgAAFAURQo5NptNkyZN0iOPPKLdu3fr/PnzqlSpkmJjY1W3bt1CbeuHH37QkiVL9M033+jw4cOqV6+e1q1b57bM2LFjtWbNmlzrLlq0SO3bty9KCwAAwHAFDjmpqamaMGGCevfurU6dOkmS6tWrp3r16rmW2bx5s2bMmKFJkyapcuXKBdru4cOHtXXrVjVt2lROp1OWZeW5XK1atfTaa6+5Tatfv35BywcAAL8xBb7xeNWqVTp06JDatWuX7zLt2rXTf/7zH7dLWDcSFxenrVu3avbs2WrcuHG+ywUFBalZs2ZufypUqFDg5wEAAL8tBQ4569evV9++feXvn//JH39/f/Xt27dQX+Bpt/P1WQAAoOQV+HLVsWPHFBMTc8PlGjdurHnz5hWrqLwcP35cd955pzIyMhQREaERI0aoS5cuxd6uv3/Jhyy73Xb1H7ar9y8Z55eW7HZbqew/b8AY+jY/P7vb3yYyvUfT+zP+GCN5xXGmwCHH4XBc9yyOa4P+/srOzi5WUddq1KiRYmJi1KBBA6Wnp2vlypUaOXKk3njjDXXr1q3I27XbbapcuXwJVurOz26Xv79fqW3fU/x+OfsWHBzk4UpKH2Po20JCynq6hFJneo+m92fqMUbyjuNMgUNOWFiYkpOT1aJFi+sud/jwYVWtWrXYhf3aoEGD3B7HxcWpf//+mj17drFCjtNpKS3tUnHLyyUgwE/BwUFyOJ3KznaU+PY9zeF0SpIuXMjQlSvm9Scxhr7Oz8+ukJCySku7LIfD6elySoXpPZren+nHGKn0jjMhIWULfIavwCGnZcuWeuedd/TAAw8oICAgz2WuXLmilStXqlWrVgXdbJHY7Xbdfffdmj59ujIyMhQUVPSUmJ1d8i8e1863lO+7xXzaLy05nVap7D9vwBiaweFwGt2fZH6PpvZn/DFG8orjTIEvkg0aNEjHjh3TqFGjdOrUqVzzT506pZEjR+rYsWN65JFHSrLGPBn7QwEAAEpEgc/kNGzYUBMnTtTLL7+szp07Kzo62vUlnSdPntT+/ftlWZZeeuklRUZGllrBkuR0OvXRRx/ptttuK9ZZHAAAYK5CfeJxv379dNttt+kvf/mLdu/era+//lqSVLZsWbVr105Dhw5Vs2bNClXA5cuXtXXrVklXw9KFCxe0ceNGSVcvkV2+fFljx45VfHy8ateurdTUVK1cuVL79+9XUlJSoZ4LAAD8dhT6ax2aN2+uBQsWyOl06ueff5YkVa5cucifd3P27FmNHj3abVrO4+XLlysyMlLBwcGaO3euzp07p4CAAEVHR2vRokXX/WBCAADw21ak766Srt78W6VKlWIXULNmTX333XfXXWb+/PnFfh4AAPDbYuanLAEAgN88Qg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwksdDzg8//KCJEyeqZ8+eioqKUnx8fJ7Lbd26Vb169VJMTIy6du2qFStW3ORKAQCAL/F4yDl8+LC2bt2qOnXqqH79+nkus2fPHo0YMUJRUVFatGiR7r//fk2ePFmrVq26ydUCAABf4e/pAuLi4tSlSxdJ0tixY7V///5cy8ydO1dRUVGaMmWKJCk2Nlb/+9//9MYbb6hPnz6y2z2e1QAAgJfxeDq4UUDJysrSrl271L17d7fpPXr0UEpKig4ePFia5QEAAB/l8TM5N3L8+HFduXJF9erVc5veoEEDSdKRI0cUHR1d5O37+5d8zrPbbVf/YZNsNluJb9/jfmnJbreVyv7zBoyhb/Pzs7v9bSLTezS9P+OPMZJXHGe8PuSkpqZKkkJCQtym5zzOmV8UdrtNlSuXL3pxN+Bnt8vf36/Utu8pfr+cfQsODvJwJaWPMfRtISFlPV1CqTO9R9P7M/UYI3nHccbrQ06O/JJucRKw02kpLe1SkdfPT0CAn4KDg+RwOpWd7Sjx7Xuaw+mUJF24kKErV8zrT2IMfZ2fn10hIWWVlnZZDofT0+WUCtN7NL0/048xUukdZ0JCyhb4DJ/Xh5yKFStKyn3GJi0tTVLuMzyFlZ1d8i8e1863JMuySnz7HvdLS06nVSr7zxswhmZwOJxG9yeZ36Op/Rl/jJG84jjj9Rc7a9eurYCAAB09etRtenJysiTl+7ZzAADw2+b1IScwMFCxsbHasGGD2/R169YpLCxMUVFRHqoMAAB4M49frrp8+bK2bt0qSTp58qQuXLigjRs3SpJatmyp0NBQjRw5UgMGDNCECRPUo0cPffXVV1q1apUmTZrEZ+QAAIA8eTzknD17VqNHj3ablvN4+fLlatWqlZo3b6558+ZpxowZWrt2rW655RZNmDBBffv29UTJAADAB3g85NSsWVPffffdDZfr0KGDOnTocBMqAgAAJuBaDwAAMBIhBwAAGMnjl6sAAMiP8V/rgFJFyAEAeB2bzSan0zL+ax1Qugg5AACvY7fbZLfbtPKjQzp19qKnyylxDW8NVbc2dV1fYonSQcgBAHit0+cu6WTKBU+XUeKqhZbzdAm/CWZe7AQAAL95hBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGMknQs7q1asVGRmZ689rr73m6dIAAICX8vd0AYWxePFiVahQwfW4evXqHqwGAAB4M58KOY0bN1ZoaKinywAAAD7AJy5XAQAAFJZPncmJj4/Xzz//rBo1aqhfv356/PHH5efnV6xt+vuXfM6z221X/2GTbDZbiW/f435pyW63lcr+8waMoW/z87O7/W0i03v8rbwGJUP7k7ziOOMTIScsLExPPPGEmjZtKpvNpk2bNmnWrFk6deqUJk6cWOTt2u02Va5cvgQrdednt8vfv3ghzBv52a/+sAYHB3m4ktLHGPq2kJCyni6h1Jneo7GvQdsvIdXQ/iTvOM74RMhp166d2rVr53p81113qUyZMnrzzTc1bNgwVatWrUjbdTotpaVdKqkyXQIC/BQcHCSH06nsbEeJb9/THE6nJOnChQxduWJefxJj6Ov8/OwKCSmrtLTLcjicni6nVJjeo/GvQevqmJnan1R6x5mQkLIFPoPpEyEnL/fcc4+WLl2qb7/9tsghR5Kys0v+4ODa+ZZkWVaJb9/jfmnJ6bRKZf95A8bQDA6H0+j+JHN7/K28BiVD+5O84jhj5sVcAADwm+ezIWf9+vXy8/NTVFSUp0sBAABeyCcuVyUkJCg2NlYRERGSpM8++0zvvfeeBg4cqLCwMA9XBwAAvJFPhJy6devq/fff108//SSn06lbb71V48aN08MPP+zp0gAAgJfyiZAzYcIET5cAAAB8jM/ekwMAAHA9hBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJJ8JOceOHVNCQoKaNWum1q1ba/LkycrIyPB0WQAAwEv5e7qAgkhLS9OgQYNUo0YNzZ49W+fOndPUqVN1/vx5vfbaa54uDwAAeCGfCDl/+9vflJaWprVr1yo0NFSS5Ofnp2effVbDhw9X/fr1PVwhAADwNj5xuWrbtm1q3bq1K+BI0u9//3sFBgZq69atHqwMAAB4K584k3PkyBH16dPHbVpgYKBq166tI0eOFHm7drtNoaHli1teLjbb1b8TekbL4bRKfPue5me/2mBwcJCCg83r76qrPTKGvq1ixbKeLqHUmduj2a/BAP+r5xgS7jOzP+nXx5kyKl++TIlt1/7LdgvCJ0JOWlqaQkJCck0PCQlRampqkbdrs9nk51fwnVVYweUCS23b3uDqD1rp7T9vwBj6NrvdJ05WF4vpPZr+GjS9P8mzP6M+/eqwLEs2m7kHaAAAUHQ+EXJCQkKUlpaWa3p6enqeZ3gAAAB8IuTUr18/1703WVlZOn78OO+sAgAAefKJkNO+fXvt2rVLP//8s2vaJ598oqysLHXo0MGDlQEAAG9lsyzL62/rTktLU3x8vMLDwzVixAidPXtW06ZN01133cWHAQIAgDz5RMiRrn6tw+TJk/Xll18qKChI8fHxevbZZxUUFOTp0gAAgBfymZADAABQGD5xTw4AAEBhEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkFMIP/zwgyZOnKiePXsqKipK8fHxBV53zZo16tatm2JiYhQfH68NGzaUYqVFV9QeH374YUVGRub6c+3XcXjShg0bNGLECHXo0EHNmjVTjx499M4778jpdN5wXV8Zv6L26AvjJ0n//Oc/NWDAAMXGxio6OlqdO3fW1KlTlZ6efsN1fWUMi9qjr4zhtS5evKj27dsrMjJS+/btu+HyvjKOOQrTn6+M4erVq/OssyAfznuzx8+/VLdumMOHD2vr1q1q2rSpnE6nCvoRQxs3btTYsWM1ZMgQtW3bVp9++qmeeuopVahQQXfddVcpV104Re1Rkm6//XaNGTPGbVrNmjVLusQiW7ZsmWrUqKHnn39eVapU0e7du/XKK6/oxx9/zFX3r/nS+BW1R8n7x0+SUlNT1bx5cw0aNEghISE6fPiwkpKSdPjwYS1dujTf9XxpDIvao+QbY3itefPmyeFwFGhZXxrHHIXpT/KtMVy8eLEqVKjgely9evXrLu+R8bNQYA6Hw/XvMWPGWN27dy/Qet26dbMSExPdpj322GNW3759S7S+klDUHgcMGGANGTKktMoqEWfPns01bcqUKVZMTIyVmZmZ73q+NH5F7dEXxi8/7777rhUREWH99NNP+S7jS2OYl4L06ItjmJycbDVr1sxauXKlFRERYe3du/e6y/vaOBa2P18Zww8++MCKiIjI83hzPZ4YPy5XFYLdXvjd9eOPP+ro0aO5LvvEx8dr7969OnfuXEmVVyKK0qOvCA0NzTWtUaNGyszM1Pnz5/Ncx9fGryg9+rpKlSpJkrKzs/Oc72tjmJcb9eirXnnlFfXv319169a94bK+OI6F6c90nho/c/9H8xJHjx6VJNWrV89tev369WVZlmu+Cb744gs1a9ZMMTExGjBggP71r395uqQb+vLLL1WpUiVVqVIlz/kmjN+NeszhS+PncDiUmZmpAwcOaO7cuerUqZPCw8PzXNZXx7AwPebwpTHcuHGjDh06pJEjRxZoeV8bx8L2l8OXxjA+Pl6NGjVS586d9Ze//OW6l+U8NX7ck1PKUlNTJUkhISFu0ytWrOg239e1aNFCPXv21K233qrTp09ryZIlevTRR/XWW2+pefPmni4vT/v27dPq1as1cuRI+fn55bmMr49fQXqUfG/8OnXqpFOnTkmS2rVrpxkzZuS7rK+OYWF6lHxrDC9fvqxp06bp6aefVnBwcIHW8aVxLEp/ku+MYVhYmJ544gk1bdpUNptNmzZt0qxZs3Tq1ClNnDgxz3U8NX6EnJvEZrO5PbZ+uaH32um+KjEx0e1xx44dFR8fr3nz5mnRokUeqip/KSkpSkxMVExMjAYPHnzD5X1x/ArTo6+N38KFC3Xp0iUlJydr3rx5GjZsmJYtW3bdIOdrY1jYHn1pDOfPn68qVaqod+/ehV7XF8axqP35yhi2a9dO7dq1cz2+6667VKZMGb355psaNmyYqlWrlu+6N3v8uFxVyvJLqWlpaZJyp1pTlCtXTh06dNCBAwc8XUou6enpGjx4sIKCgjR//nwFBATku6yvjl9hesyLN4+fJDVs2FC33367+vXrpzlz5mj37t365JNP8lzWV8ewMD3mxVvH8OTJk1q6dKkSExN14cIFpaWl6dKlS5KkS5cu6eLFi3mu5yvjWNT+8uKtY5iXe+65Rw6HQ99++22e8z01fpzJKWU51x+PHj2q+vXru6YfOXJENpst1/VJk1iFePv5zZKZmanhw4frzJkzevfdd1W5cuXrLu+L41fYHvPjjeOXl0aNGsnPz0/Hjx/Pc74vjuG1btRjfrxxDE+cOKErV65oyJAhueYNHDhQTZs21XvvvZdrnq+MY1H7y483jmFReGr8CDmlrFatWqpXr57Wr1+vrl27uqavW7dOTZo0yfPdMCa4dOmStm7dqpiYGE+X4pKdna3Ro0fr0KFDevvtt294E6fke+NXlB7z4o3jl589e/bI4XDk+1kivjaGeblRj3nx1jFs1KiRli9f7jbt22+/1dSpU/Xyyy/nW6+vjGNR+8uLt45hXtavXy8/Pz9FRUXlOd9T40fIKYTLly9r69atkq6ekrxw4YI2btwoSWrZsqVCQ0M1btw4rV27VgcPHnStl5iYqKeeekq1a9dWmzZt9Nlnn+nzzz/X4sWLPdLH9RSlx3//+99asmSJunbtqho1auj06dNatmyZUlJS9MYbb3isl2tNmjRJmzdv1nPPPaeMjAx9/fXXrnkNGjRQcHCwz49fUXr0lfGTpFGjRik6OlqRkZEKCgrSoUOHtHjxYkVGRqpLly6S5PNjWJQefWkMQ0JC1KpVqzznNW7cWI0bN5bku+NY1P58aQwTEhIUGxuriIgISdJnn32m9957TwMHDlRYWJgk7xk/Qk4hnD17VqNHj3ablvN4+fLlatWqlZxOZ6630d1zzz3KyMjQggULtGTJEtWpU0czZ870yk/oLEqPYWFhysrK0owZM3T+/HmVLVtWzZs318svv6wmTZrc1PqvZ/v27ZKk6dOn55pnyvgVpUdfGT9JatKkidavX6+FCxfKsiyFh4erX79+SkhIUGBgoCT5/BgWpUdfGsOC8vVxvBFfHsO6devq/fff108//SSn06lbb71V48aN08MPP+xaxlvGz2aZcsEPAADgV3h3FQAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAJ+VnJyspKQknThxIte8sWPHKi4uzgNVAfAWhBwAPis5OVlz5szRyZMnc80bMWKE5syZ44GqAHgLvrsKgFe5fPmyypYtW+zt1K5duwSqAeDLOJMDwGOSkpIUGRmpAwcOKDExUS1atFDXrl21b98+PfXUU4qLi1OTJk0UFxenp59+2u2MzerVq11fHjtw4EBFRkYqMjJSq1evlpT35arIyEhNmjRJa9eu1T333KOmTZvqvvvu0+bNm3PV9umnn6pHjx6Kjo5W586d9eabb7rqBeAbOJMDwOOeeOIJ3Xvvverfv78uXbqkkydPqm7duurevbsqVqyolJQUrVy5Ug888ID+8Y9/KDQ0VB07dtTTTz+tGTNmaOLEiWrcuLGkG5/B2bJli/bt26fExESVK1dOixcv1qhRo7Rx40bVqlVLkrRt2zY98cQTuvPOOzVr1ixlZ2dr6dKlOnPmTKnvCwAlh5ADwON69eqlxMREt2ndunVz/dvhcKhjx45q27at1q1bp4EDByo0NFR16tSRJDVo0EDNmjUr0HNlZmZq2bJlCg4OliQ1btxY7dq104YNGzRkyBBJ0uzZs1W9enUtWbJEgYGBkqR27dpxIzPgYwg5ADzu7rvvdnt88eJFzZs3Tx9//LFOnjwph8PhmnfkyJFiPVerVq1cAUeSqlatqipVqrguhV26dEn79+/XgAEDXAFHksqXL6+4uDjX5TAA3o+QA8DjqlWr5vb4mWee0a5duzRixAjFxMSofPnystlsGjJkiDIzM4v1XJUqVco1LTAw0LXdtLQ0WZalKlWq5Four2kAvBchB4BXSU9P15YtWzRq1CjX5SNJysrKUmpqaqk/f0hIiGw2m86ePZtrHvfkAL6Fd1cB8Co2m02WZbldKpKkVatWuV22kuRaJiMjo8Sev1y5coqOjtann36qrKws1/SLFy/m+S4sAN6LMzkAvEpwcLBatGihJUuWqHLlygoPD9cXX3yh999/XyEhIW7L3nbbbZKk9957T+XLl1eZMmVUs2ZNVa5cuVg1JCYmaujQoUpISNCgQYPkcDi0ZMkSlS9f/qacTQJQMjiTA8DrvP7662rVqpWmT5+uUaNGaf/+/Vq2bJkqVKjgtlytWrU0btw4HTp0SAMHDtQDDzxQImdb2rdvr6SkJJ0/f15PPvmkpk2bpi5duiguLi5X0ALgvWyWZVmeLgIAvN2VK1fUq1cvVa9eXUuXLvV0OQAKgMtVAJCHcePGqW3btgoLC9OZM2e0cuVKHTlyROPHj/d0aQAKiJADAHm4ePGiXn31VZ07d04BAQGKiorSwoUL1aZNG0+XBqCAuFwFAACMxI3HAADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICR/h+TCrM49qwO5AAAAABJRU5ErkJggg==",
                        "text/plain": "\u003cFigure size 640x480 with 1 Axes\u003e"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.title('Number of reviews with a given rating')\n",
                "sns.histplot(products['rating'])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eproduct_id\u003c/th\u003e\n      \u003cth\u003esummary\u003c/th\u003e\n      \u003cth\u003ereview\u003c/th\u003e\n      \u003cth\u003erating\u003c/th\u003e\n      \u003cth\u003esentiment\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e387\u003c/th\u003e\n      \u003ctd\u003e9104\u003c/td\u003e\n      \u003ctd\u003eKids love these\u003c/td\u003e\n      \u003ctd\u003eI love these because there is not too much sug...\u003c/td\u003e\n      \u003ctd\u003e5.0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1148\u003c/th\u003e\n      \u003ctd\u003e3157\u003c/td\u003e\n      \u003ctd\u003ePure sweetness with no unpleasant flavor or af...\u003c/td\u003e\n      \u003ctd\u003eThis natural very healthy sweetener is absolut...\u003c/td\u003e\n      \u003ctd\u003e5.0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1122\u003c/th\u003e\n      \u003ctd\u003e5743\u003c/td\u003e\n      \u003ctd\u003eHorrible Flavor but Good Protein\u003c/td\u003e\n      \u003ctd\u003eThis stuff tastes like mushrooms to me and I h...\u003c/td\u003e\n      \u003ctd\u003e2.0\u003c/td\u003e\n      \u003ctd\u003e-1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1171\u003c/th\u003e\n      \u003ctd\u003e8082\u003c/td\u003e\n      \u003ctd\u003egreen mountain coffee\u003c/td\u003e\n      \u003ctd\u003eI love the keurig format of coffee.  Now and a...\u003c/td\u003e\n      \u003ctd\u003e5.0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e829\u003c/th\u003e\n      \u003ctd\u003e5931\u003c/td\u003e\n      \u003ctd\u003eGROSS! TASTES LIKE STALE BREAD\u003c/td\u003e\n      \u003ctd\u003eThis water is disgusting and tastes like anoth...\u003c/td\u003e\n      \u003ctd\u003e1.0\u003c/td\u003e\n      \u003ctd\u003e-1\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e",
                        "text/plain": "      product_id                                            summary  \\\n387         9104                                    Kids love these   \n1148        3157  Pure sweetness with no unpleasant flavor or af...   \n1122        5743                   Horrible Flavor but Good Protein   \n1171        8082                              green mountain coffee   \n829         5931                     GROSS! TASTES LIKE STALE BREAD   \n\n                                                 review  rating  sentiment  \n387   I love these because there is not too much sug...     5.0          1  \n1148  This natural very healthy sweetener is absolut...     5.0          1  \n1122  This stuff tastes like mushrooms to me and I h...     2.0         -1  \n1171  I love the keurig format of coffee.  Now and a...     5.0          1  \n829   This water is disgusting and tastes like anoth...     1.0         -1  "
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating \u003e 3 else -1)\n",
                "products.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we can see that the dataset contains an extra column called **sentiment** which is either positive (+1) or negative (-1)."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Build the word count vector for each review"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let us explore a specific example of a food product. We have information about the product, the review left, and both the rating that was given and the sentiment label we computed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Rating : 5.0 (Sentiment=1)\nSummary: Tasty and inexpensive\nReview : I really like this cereal. The flavor is slightly nutty and it doesn't get soggy quickly in almond milk. It reminds me of Honey Smacks without any sugar. My favorite way to eat it is with some chopped raw almonds, flax seeds and a touch of agave nectar.\n"
                }
            ],
            "source": [
                "example_product = products.iloc[21]\n",
                "print(f\"Rating : {example_product['rating']} (Sentiment={example_product['sentiment']})\")\n",
                "print(\"Summary:\", example_product[\"summary\"])\n",
                "print(\"Review :\", example_product[\"review\"])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To work with the text data, we will need to turn it into a vector of word counts. In other words, we will be making a feature for every word that could possibly appear in the data, and the value for that feature for one example would be the number of times that word appears in that example. \n",
                "\n",
                "To accomplish this, we will need to do two data transformation:\n",
                "\n",
                "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
                "2. Transform the reviews into word-counts.\n",
                "\n",
                "\n",
                "\n",
                "\u003e **Aside**. In this assignment, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. \n",
                "\u003e \n",
                "\u003e If you are curious in learning how to handle these complexities in practice, you might be interested in  researching more about tokenization and NLP like [this page](https://towardsdatascience.com/tokenization-for-natural-language-processing-a179a891bad4) shows. Note that you do not need to do any of that stuff for this assignment.\n",
                "\n",
                "So first, we remove punctuation with the code in the next cell."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "def remove_punctuation(text):\n",
                "    \"\"\"\n",
                "    Remove any punctuation in text. Python has a default set of \n",
                "    punctuation marks, stored in string.punctuation, that contains\n",
                "    !\"#$%\u0026'()*+, -./:;\u003c=\u003e?@[\\]^_`{|}~\n",
                "    \"\"\"\n",
                "    if type(text) is str:\n",
                "        return text.translate(str.maketrans('', '', string.punctuation))\n",
                "    else:\n",
                "        return ''\n",
                "    \n",
                "products['review_clean'] = products['review'].apply(remove_punctuation)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we use scikit-learn's [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to get counts for each word. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e002\u003c/th\u003e\n      \u003cth\u003e004\u003c/th\u003e\n      \u003cth\u003e004oz\u003c/th\u003e\n      \u003cth\u003e032\u003c/th\u003e\n      \u003cth\u003e051\u003c/th\u003e\n      \u003cth\u003e100gr\u003c/th\u003e\n      \u003cth\u003e10112013seller\u003c/th\u003e\n      \u003cth\u003e11\u003c/th\u003e\n      \u003cth\u003e1258201cm\u003c/th\u003e\n      \u003cth\u003e128\u003c/th\u003e\n      \u003cth\u003e...\u003c/th\u003e\n      \u003cth\u003eyourself\u003c/th\u003e\n      \u003cth\u003eyucateco\u003c/th\u003e\n      \u003cth\u003eyuckgot\u003c/th\u003e\n      \u003cth\u003eyumyum\u003c/th\u003e\n      \u003cth\u003eyup\u003c/th\u003e\n      \u003cth\u003ezabars\u003c/th\u003e\n      \u003cth\u003ezico\u003c/th\u003e\n      \u003cth\u003esentiment\u003c/th\u003e\n      \u003cth\u003ereview_clean\u003c/th\u003e\n      \u003cth\u003esummary\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e387\u003c/th\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003eI love these because there is not too much sug...\u003c/td\u003e\n      \u003ctd\u003eKids love these\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1148\u003c/th\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003eThis natural very healthy sweetener is absolut...\u003c/td\u003e\n      \u003ctd\u003ePure sweetness with no unpleasant flavor or af...\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1122\u003c/th\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e-1\u003c/td\u003e\n      \u003ctd\u003eThis stuff tastes like mushrooms to me and I h...\u003c/td\u003e\n      \u003ctd\u003eHorrible Flavor but Good Protein\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1171\u003c/th\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003eI love the keurig format of coffee  Now and al...\u003c/td\u003e\n      \u003ctd\u003egreen mountain coffee\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e829\u003c/th\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e-1\u003c/td\u003e\n      \u003ctd\u003eThis water is disgusting and tastes like anoth...\u003c/td\u003e\n      \u003ctd\u003eGROSS! TASTES LIKE STALE BREAD\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e5 rows × 2334 columns\u003c/p\u003e\n\u003c/div\u003e",
                        "text/plain": "      002  004  004oz  032  051  100gr  10112013seller  11  1258201cm  128  \\\n387     0    0      0    0    0      0               0   0          0    0   \n1148    0    0      0    0    0      0               0   0          0    0   \n1122    0    0      0    0    0      0               0   0          0    0   \n1171    0    0      0    0    0      0               0   0          0    0   \n829     0    0      0    0    0      0               0   0          0    0   \n\n      ...  yourself  yucateco  yuckgot  yumyum  yup  zabars  zico  sentiment  \\\n387   ...         0         0        0       0    0       0     0          1   \n1148  ...         0         0        0       0    0       0     0          1   \n1122  ...         0         0        0       0    0       0     0         -1   \n1171  ...         0         0        0       0    0       0     0          1   \n829   ...         0         0        0       0    0       0     0         -1   \n\n                                           review_clean  \\\n387   I love these because there is not too much sug...   \n1148  This natural very healthy sweetener is absolut...   \n1122  This stuff tastes like mushrooms to me and I h...   \n1171  I love the keurig format of coffee  Now and al...   \n829   This water is disgusting and tastes like anoth...   \n\n                                                summary  \n387                                     Kids love these  \n1148  Pure sweetness with no unpleasant flavor or af...  \n1122                   Horrible Flavor but Good Protein  \n1171                              green mountain coffee  \n829                      GROSS! TASTES LIKE STALE BREAD  \n\n[5 rows x 2334 columns]"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Make counts\n",
                "vectorizer = CountVectorizer()\n",
                "count_matrix = vectorizer.fit_transform(products['review_clean'])\n",
                "\n",
                "# Get the feature names (e.g., one per word)\n",
                "features = vectorizer.get_feature_names_out()\n",
                "\n",
                "# Make a new DataFrame with the counts information\n",
                "product_data = pd.DataFrame(count_matrix.toarray(),\n",
                "        index=products.index,\n",
                "        columns=features)\n",
                "\n",
                "# Add the old columns to our new DataFrame. \n",
                "# We won't use review_clean and the summary in our model, but we will keep\n",
                "# them to look at later.\n",
                "product_data['sentiment'] = products['sentiment']\n",
                "product_data['review_clean'] = products['review_clean']  \n",
                "product_data['summary'] = products['summary']\n",
                "\n",
                "product_data.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We have now created a lot of features to work with! Note that in the table above, we will have one feature for each word that appeared in the data and the value for that feature is the count of that word in that review. So for example, if review 5 had the word \"dog\" in it 3 times, the value in row 5 and column \"dog\" would be 3.\n",
                "\n",
                "## Split data into training, validation and test sets."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's perform a train/validation/test split with 80% of the data in the training set, 10% of the data in the validation set, 10% test. Note that we use `random_state=3` so that everyone gets the same result."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data, test_and_validation_data = train_test_split(product_data, test_size=0.2, random_state=3)\n",
                "validation_data, test_data = train_test_split(test_and_validation_data, test_size=0.5, random_state=3)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Baseline: Majority class prediction\n",
                "\n",
                "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points.\n",
                "\n",
                "To \"train\" the majority class classifier, you should simply find the most frequent target in the training data.\n",
                "\n",
                "### **Question 1:** Majority class classifier\n",
                "* Compute the most frequent label and store it in a variable called `majority_label`.\n",
                "* What is the validation accuracy of the majority class classifer. Store your result as a number between 0 and 1 in a variable called `majority_classifier_validation_accuracy`.\n",
                "  \n",
                "  *Hint:* pandas allows you to take the sum of a boolean series - true values are equal to 1, false values are equal 0."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q1_majority_classifier) ###\n",
                "\n",
                "# TODO \"Train\" a majority class classifier and calculate its validation accuracy\n",
                "\n",
                "majority_label = None\n",
                "majority_classifier_validation_accuracy = None"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Train a sentiment classifier with logistic regression\n",
                "\n",
                "We will now use logistic regression to create a sentiment classifier on the training data. This model will use the columns representing word counts as features and the column **sentiment** as the target. We will set **no regularization penalty**, and set `random_state=1` to get the same answer as everyone else.\n",
                "\n",
                "You can see scikit-learn's documentation for LogisticRegression [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Note that the parameter for this class to control regularization is named `C` and it represents the inverse of the penalty strength. In other words $C = \\frac{1}{\\lambda}$. By default, $C=1.0$, which means if you don't specify `C` the model will have regularization. To have very little regularization, you have to specify `C` to be a very large number (corresponding to a very small $\\lambda$). (Note that technically, the better way to do this would be to pass in the parameter `penalty='none'` into the Logistic Regression model. However, in this assignment, for consistency across sub-parts, we use an L2 penalty with a large C value here.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Note: C = 1/Lambda. Setting C to a really high value is the same as setting lambda = 0\n",
                "sentiment_model = LogisticRegression(penalty='l2', C=1e23, random_state=1)\n",
                "sentiment_model.fit(train_data[features], train_data['sentiment'])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's look at some of the coefficients and the corresponding words. The weights are stored in a `coef_` property: "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "coefficients = sentiment_model.coef_\n",
                "\n",
                "print('Smallest coefficient', coefficients.min())\n",
                "print('Largest coefficient:', coefficients.max())"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Question 2:** Most Positive/Negative Word\n",
                "For the sentiment model we trained above, compute the word with the most negative weight and the word with the most positive weight.\n",
                "\n",
                "Store your results in the variables `most_negative_word` and `most_positive_word`.\n",
                "\n",
                "While you only need to write code to compute the most negative and most positive, we also recommend printing out the words with the highest magnitude coefficients to make sure they make sense.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q2_most_pos_neg_words) ###\n",
                "\n",
                "# TODO Find the most positive word and most negative word in the sentiment_model\n",
                "\n",
                "most_negative_word = None\n",
                "most_positive_word = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('Most negative word:', most_negative_word)\n",
                "print('Most positive word:', most_positive_word)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Making predictions with logistic regression\n",
                "\n",
                "Now that a model is trained, we can make predictions on the **validation data**. In this first section, we will restrict the examples we are looking at to 3 examples in the validation dataset. We refer to this set of 3 examples as the **sample_data**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "sample_data = validation_data[8:11]\n",
                "sample_data[['sentiment', 'review_clean', 'summary']]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Predicting sentiment\n",
                "Let's start by predicting the probability of positive/negative sentiment of the 3 examples in the `sample_data`. The `predict_proba` method on the `LogisticRegression` class outputs a probability for each class possible.\n",
                "\n",
                "The output has one row for each example. Each row is an array of 2 numbers, the first is the predictor's prediction for the probability it is a negative sentiment example, and the second is the probability of it being a positive sentiment example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('  Prob Negative, Prob Positive')\n",
                "print(sentiment_model.predict_proba(sample_data[features]))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We are also able to predictions labels (i.e., $\\pm1$, not just probabilities) using the `predict` function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('Predicted labels')\n",
                "print(sentiment_model.predict(sample_data[features]))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Question 3:** Find the review predicted to be most positive (and negative)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now turn to examining the full **validation_data** dataset \u003cspan style=\"color:red\"\u003e(not sample_data)\u003c/span\u003e, , and use `sklearn` to form predictions on all of the data points for faster performance.\n",
                "\n",
                "Using the `sentiment_model`, find the review in the **validation_data** with the **highest probability** of being classified as a **positive review**. Also, find the review with the **highest probability** of being classified as a **negative review**. We refer to these as the \"most positive review\" and \"most negative review\" respectively. Store the `review_clean` column value for each of these rows in `most_positive_review` and `most_negative_review` variables respectively.\n",
                "\n",
                "If there is a tie for the most positive/negative reivew, you should always grab the one that appears *first* in the validation data.\n",
                "\n",
                "*Hint*: Once you know the index of the most positive/negative reviews, use the `.iloc[]` accessor on the DataFrame to get that row and find its `review_clean` value."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q3_most_positive_negative_review) ###\n",
                "\n",
                "# TODO Find the review_clean values for the most positive and most negative review\n",
                "\n",
                "most_positive_review = None\n",
                "most_negative_review = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('Most Positive Review:')\n",
                "print(most_positive_review)\n",
                "print()\n",
                "print('Most Negative Review:')\n",
                "print(most_negative_review)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Do you notice something special about those reviews? They are both pretty long! Here we just count number of words regardless of the length of the review, but clearly that can affect the results. In practice, one can use some techniques to normalize the counts to avoid prioritizing long reviews over shorter ones (we will discuss this idea in a future week).\n",
                "\n",
                "### **Question 4:** Compute validation accuracy\n",
                "Compute the validation accuracy for the model we just trained. Report the validation accuracy as a number between 0 and 1 stored in a variable called `sentiment_model_validation_accuracy`.\n",
                "\n",
                "Below, calculate the accuracy of the predictor using sklearn's [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function. Note that you should use the **predicted labels**, not the predicted probabilities."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q4_sentiment_model_accuracy) ###\n",
                "\n",
                "# TODO Find the validation accuracy of the sentiment model\n",
                "\n",
                "sentiment_model_validation_accuracy = None"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Create a confusion matrix\n",
                "\n",
                "A common tool used when analyzing the peformance of a predictor in a classification problem is to look at the confusion matrix, as well as the overall accuracy.\n",
                "\n",
                "We've created a function that will plot a confusion matrix for you given a set of inputs which are the values that should appear within each cell.\n",
                "Recall that there are four values associated with a confusion matrix: true positive, true negative, false positive, and false negative which we will abberviate as TP, TN, FP, and FN, respecitvely. In other words, for the next problem we have handled the plotting code for you that you can use, but you will need to compute the values for each of the confusion matrix dimensions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_confusion_matrix(tp, fp, fn, tn):\n",
                "    \"\"\"\n",
                "    Plots a confusion matrix using the values \n",
                "       tp - True Positive\n",
                "       fp - False Positive\n",
                "       fn - False Negative\n",
                "       tn - True Negative\n",
                "    \"\"\"\n",
                "    data = np.matrix([[tp, fp], [fn, tn]])\n",
                "\n",
                "    sns.heatmap(data,annot=True,xticklabels=['Actual Pos', 'Actual Neg']\n",
                "              ,yticklabels=['Pred. Pos', 'Pred. Neg']) "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Question 5:** Compute confusion matrix values and plot\n",
                "\n",
                "Write code below that uses the `plot_confusion_matrix` function to show the number of true positive, true negative, false positive, and false negative predictions made by your classifier on the validation set. You should store the counts for each of these values in the variables:\n",
                "* `tp`\n",
                "* `fp`\n",
                "* `fn`\n",
                "* `tn` \n",
                "\n",
                "You might find it useful to use named parameters here (i.e. you can call `plot_confusion_matrix(tp=X, fp=Y, fn=A, tn=B)` instead of having to get the order of the parameters correct).\n",
                "\n",
                "There are multiple ways to solve this. One involves iterating over every datapoint and comparing its prediction to the actual; another involves using [sklearn's confusion_matrix function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) (see the examples for an example of using that function for binary classification)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q5_confusion_matrix) ###\n",
                "\n",
                "# TODO Compute the four values tp, fp, fn, tn and plot them using plot_confusion_matrix\n",
                "\n",
                "tp = None\n",
                "fp = None\n",
                "tn = None\n",
                "fn = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_confusion_matrix(tp=tp, fp=fp, tn=tn, fn=fn)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Question 6 and 7**: Logistic Regression with L2 regularization\n",
                "\n",
                "One of the challenges of creating features from each word is that there are many more features than observations. It is easy to overfit. We will explore the effect of the regularization in this problem.\n",
                "\n",
                "Now that we have written up all the pieces needed for regularized logistic regression, let's explore the benefits of using **L2 regularization** in analyzing sentiment for product reviews. \n",
                "\n",
                "Like in the last assignment, we will train models with various levels of regularization starting with a small amount and then moving to a  large amount. The code here will have some similarities to the code you did in the last assignment, so you will find that to be a useful reference, but this problem will be slightly more complex since we ask you to compute a few values.\n",
                "\n",
                "This code will be counted as two separate questions since you will be computing slightly different values, but we will ask you to compute both of them in the same starter code to reduce code duplication (since the tasks are very similar). \n",
                "\n",
                "We first outline what you should compute for each question and then show some general implementation notes for both problems below. Your task for this problem is to fill out the code inside the loop to compute the values described below.\n",
                "\n",
                "\u003cspan style=\"color: green;\"\u003eTip!\u003c/span\u003e We recommend focusing on the values you need to compute for Q6 and then once you have that working work on the code you need to compute Q7.\n",
                "\n",
                "### **Question 6:** Coefficient Paths\n",
                "For this question we will ask you to compute the coefficent path for each of the features in the model for various values of the regularization constant.\n",
                "\n",
                "For each regularization strength, train a model using that regularization constant and create a table storing the coefficients of each learned predictor. Store the results in a `DataFrame` named `coef_table`.\n",
                "\n",
                "You should end up with an `DataFrame` with column names as `'coefficients [L2=1e-02]', ... 'coefficients [L2=1e+05]'`, and a row for each word in `features`. It should look something like the following:\n",
                "\n",
                "|     | word | coefficients [L2=1e-02] | coefficients [L2=1e+00] | ... | coefficients [L2=1e+05] |\n",
                "|-----|------|-------------------------|-------------------------|-----|-------------------------|\n",
                "| 0   |  word1 |           ...           |           ...           | ... |           ...           |\n",
                "| 1   |  word2 |           ...           |           ...           | ... |           ...           |\n",
                "| ... |  ..  |           ...           |           ...           | ... |           ...           |\n",
                "\n",
                "Before the loop, we set up `coef_table` to have the right rows and columns, but your code will need to fill out the rest.\n",
                "\n",
                "### **Question 7:** Train and Validation Accuracies\n",
                "Similar to Q6, we want you to compute the training and validation accuracy for each learned predictor and store that in a `DataFrame` called `accuracies_table`. \n",
                "\n",
                "You should end up with a `DataFrame` with column names `'l2_penalty', 'train_accuracy', 'validation_accuracy'` and a row for each L2 penalty tried. The L2 penaly should be the number (not the column name from Q7) and the accuracy values should be numbers between 0 and 1 for the appropriate accuracy. It should look something like the following:\n",
                "\n",
                "|     | l2_penalty | train_accuracy | validation_accuracy |\n",
                "|-----|------------|----------------|---------------------|\n",
                "| 0   |    0.01    |       ...      |         ...         |\n",
                "| 1   |      1     |       ...      |         ...         |\n",
                "| ... |     ..     |       ...      |         ...         |\n",
                "\n",
                "For this problem, we recommend the approach used in HW1 to build up a list of dictionaries, and then convert that to a `DataFrame` with the values described.\n",
                "\n",
                "### Implementation Details\n",
                "\n",
                "Some important notes about your implementation:\n",
                "*  When constructing a `LogisticRegression` object, make sure to use `random_state=1` to get the same results as us. We also want to avoid having an intercept term in this example, so also pass `fit_intercept=False` when constructing the `LogisticRegression` model.\n",
                "* \u003cspan style=\"color:red\"\u003eWhen constructing the LogisticRegression(...) model, the parameter `C` is the **inverse** of $\\lambda$ (i.e., $C=\\frac{1}{\\lambda}$). \u003c/span\u003e\n",
                "* Q7: To store the results of your predictor's coefficients, you will need to get the values from the `.coef_` property. Since the code for this is a little complex, we give you this line below (assumes your trained model is stored in a variable called `model`):\n",
                "  ```\n",
                "  coef_table[column_name] = model.coef_[0]\n",
                "  ```\n",
                "\n",
                "* It is okay if your code prints `ConvergenceWarnings`. This is something you would want to avoid in practice but is okay in our assignment for simplicity.\n",
                "\n",
                "* We recommend just focusing on Q6 at first and getting the code to set up the coefficients table right. Then once that's working, evaluate the models for Q7.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q6_q7_train_models) ###\n",
                "\n",
                "# TODO Fill in the loop below\n",
                "\n",
                "# Set up the regularization penalities to try\n",
                "l2_penalties = [0.01, 1, 4, 10, 1e2, 1e3, 1e5]\n",
                "l2_penalty_names = [f'coefficients [L2={l2_penalty:.0e}]' \n",
                "                    for l2_penalty in l2_penalties]\n",
                "\n",
                "# Q6: Add the coefficients to this coef_table for each model\n",
                "coef_table = pd.DataFrame(columns=['word'] + l2_penalty_names)\n",
                "coef_table['word'] = features\n",
                "\n",
                "# Q7: Set up an empty list to store the accuracies (will convert to DataFrame after loop)\n",
                "accuracy_data = []\n",
                "\n",
                "for l2_penalty, l2_penalty_column_name in zip(l2_penalties, l2_penalty_names):\n",
                "    # TODO(Q6 and Q7): Train the model. Remember to pass `fit_intercept=False` and `random_state=1` to the model.\n",
                "    \n",
                "    # TODO(Q6): Save the coefficients in coef_table\n",
                "\n",
                "    # TODO(Q7): Calculate and save the train and validation accuracies\n",
                "    \n",
                "accuracies_table = pd.DataFrame(accuracy_data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Look at coef_table\n",
                "coef_table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Look at accuracies_table\n",
                "accuracies_table"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Question 8:** Inspect Coefficients\n",
                "\n",
                "We'll now look at the **coefficients** for the model that were trained above. We will create a table of features and learned coefficients associated with each of the different L2 penalty values.\n",
                "\n",
                "Using **the coefficients trained with L2 penalty 1**, find the 5 most positive words (with largest positive coefficients). Save them to `positive_words`. Similarly, find the 5 most negative words (with largest negative coefficients) and save them to `negative_words`. The result should be the `'word'` column for the these rows. \n",
                "\n",
                "To be specific, the type of the value we are looking for is a `Series` in `pandas` which is the type of a single row or column in a `DataFrame`. When you have a `DataFrame`, it is a structure with rows and columns. When you access a single column as in `df[column_name]`, this returns a `Series` representing that one column. \n",
                "\n",
                "This means your result for each one of these variables should be a `Series` of length 5 for the respective words.\n",
                "\n",
                "\n",
                "*Hint:* You can use the `.nlargest()` and `.nsmallest()` method on an DataFrame to find the top `n` rows sorted according to the value of a specified column. Here is the documentation for [nlargest](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q8_most_positive_negative) ###\n",
                "\n",
                "\n",
                "# TODO Compute words with the 5 largest coefficients and 5 smallest coefficients\n",
                "\n",
                "positive_words = None\n",
                "negative_words = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(positive_words)\n",
                "print(negative_words)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let us observe the effect of increasing L2 penalty on the 10 words just selected. We provide you with a utility function to  plot the coefficient path."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list):\n",
                "    \"\"\"\n",
                "    Makes a plot of coefficients, given a table where rows correspond to words and\n",
                "    columns correspond to the l2 penalty, a list of positive words, a list of \n",
                "    negative words, and a list of l2 penalties.\n",
                "    \"\"\"\n",
                "    def get_cmap_value(cmap, i, total_words):\n",
                "        \"\"\"\n",
                "        Computes a nice scaling of from i=0 to i=total_words - 1\n",
                "        for the given cmap\n",
                "        \"\"\"\n",
                "        return cmap(0.8 * ((i + 1) / (total_words * 1.2) + 0.15))\n",
                "\n",
                "\n",
                "    def plot_coeffs_for_words(ax, words, cmap):\n",
                "        \"\"\"\n",
                "        Given an axes to plot on and a list of words and a cmap,\n",
                "        plots the coefficient paths for each word in words\n",
                "        \"\"\"\n",
                "        words_df = table[table['word'].isin(words)]\n",
                "        words_df = words_df.reset_index(drop=True)  # To make indices sequential\n",
                "\n",
                "        for i, row in words_df.iterrows():\n",
                "            color = get_cmap_value(cmap, i, len(words))\n",
                "            ax.plot(xx, row[row.index != 'word'], '-',\n",
                "                    label=row['word'], linewidth=4.0, color=color)\n",
                "\n",
                "    # Make a canvas to draw on\n",
                "    fig, ax = plt.subplots(1, figsize=(10, 6))\n",
                "   \n",
                "    # Set up the xs to plot and draw a line for y=0\n",
                "    xx = l2_penalty_list\n",
                "    ax.plot(xx, [0.] * len(xx), '--', linewidth=1, color='k')\n",
                "\n",
                "    # Plot the positive and negative coefficient paths\n",
                "    cmap_positive = plt.get_cmap('Reds')\n",
                "    cmap_negative = plt.get_cmap('Blues')\n",
                "    plot_coeffs_for_words(ax, positive_words, cmap_positive)\n",
                "    plot_coeffs_for_words(ax, negative_words, cmap_negative)\n",
                "\n",
                "    # Set up axis labels, scale, and legend  \n",
                "    ax.legend(loc='best', ncol=2, prop={'size':16}, columnspacing=0.5 )\n",
                "    ax.set_title('Coefficient path')\n",
                "    ax.set_xlabel('L2 penalty ($\\lambda$)')\n",
                "    ax.set_ylabel('Coefficient value')\n",
                "    ax.set_xscale('log')\n",
                "\n",
                "\n",
                "make_coefficient_plot(coef_table, positive_words, negative_words, l2_penalty_list=l2_penalties)"
            ]
        }
    ]
}
